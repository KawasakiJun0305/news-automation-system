# API ä»•æ§˜æ›¸ - API Specification

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

```
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼šDigest Daily
ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼š1.0
ä½œæˆæ—¥ï¼š2026-01-29
å¯¾è±¡ï¼šå†…éƒ¨ APIï¼ˆã‚¯ãƒ©ã‚¹/é–¢æ•°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
```

---

## 1ï¸âƒ£ API æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€**å†…éƒ¨ API**ï¼ˆPython ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ï¼‰ã®ä»•æ§˜ã‚’å®šç¾©ã—ã¾ã™ã€‚

REST API ã§ã¯ãªãã€Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚

---

## 2ï¸âƒ£ Data Fetcher API

### 2.1 DataFetcher ã‚¯ãƒ©ã‚¹

```python
class DataFetcher:
    """
    è¤‡æ•°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
```

#### ãƒ¡ã‚½ãƒƒãƒ‰ï¼šfetch_all()

```python
async def fetch_all() -> List[UniversalArticle]:
    """
    å…¨ç™»éŒ²ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’éåŒæœŸå–å¾—
    
    æˆ»ã‚Šå€¤ï¼š
        List[UniversalArticle]ï¼šå–å¾—ã—ãŸè¨˜äº‹ãƒªã‚¹ãƒˆ
    
    ä¾‹å¤–ï¼š
        Exceptionï¼šå…¨ã‚½ãƒ¼ã‚¹ãŒå¤±æ•—ã—ãŸå ´åˆ
    
    ä½¿ç”¨ä¾‹ï¼š
        fetcher = DataFetcher()
        articles = await fetcher.fetch_all()
        print(f"{len(articles)} ä»¶å–å¾—")
    """
```

#### ãƒ¡ã‚½ãƒƒãƒ‰ï¼šfetch_by_source()

```python
async def fetch_by_source(source_name: str) -> List[UniversalArticle]:
    """
    ç‰¹å®šã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã¿è¨˜äº‹ã‚’å–å¾—
    
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
        source_name (str)ï¼šã‚½ãƒ¼ã‚¹åï¼ˆ"newsapi", "rss", ãªã©ï¼‰
    
    æˆ»ã‚Šå€¤ï¼š
        List[UniversalArticle]ï¼šå–å¾—ã—ãŸè¨˜äº‹ãƒªã‚¹ãƒˆ
    
    ä¾‹å¤–ï¼š
        ValueErrorï¼šæœªçŸ¥ã®ã‚½ãƒ¼ã‚¹å
        Exceptionï¼šã‚½ãƒ¼ã‚¹å–å¾—å¤±æ•—
    
    ä½¿ç”¨ä¾‹ï¼š
        articles = await fetcher.fetch_by_source('newsapi')
    """
```

---

## 3ï¸âƒ£ Article Processor API

### 3.1 DataNormalizer ã‚¯ãƒ©ã‚¹

```python
class DataNormalizer:
    """
    è¤‡æ•°ã‚½ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ UniversalArticle ã«çµ±ä¸€
    """

    @staticmethod
    def normalize_articles(raw_articles: dict) -> List[UniversalArticle]:
        """
        è¤‡æ•°ã‚½ãƒ¼ã‚¹ã®è¨˜äº‹ã‚’ã¾ã¨ã‚ã¦æ­£è¦åŒ–
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            raw_articles (dict)ï¼š{
                'newsapi': [è¨˜äº‹, è¨˜äº‹, ...],
                'rss': {
                    'nikkei': [ã‚¨ãƒ³ãƒˆãƒª, ...],
                    'nhk': [ã‚¨ãƒ³ãƒˆãƒª, ...]
                }
            }
        
        æˆ»ã‚Šå€¤ï¼š
            List[UniversalArticle]ï¼šæ­£è¦åŒ–æ¸ˆã¿è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        ä½¿ç”¨ä¾‹ï¼š
            articles = DataNormalizer.normalize_articles(raw_data)
        """
```

---

### 3.2 ArticleFilter ã‚¯ãƒ©ã‚¹

```python
class ArticleFilter:
    """
    è¨˜äº‹ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    """

    @staticmethod
    def filter_articles(articles: List[UniversalArticle]) -> List[UniversalArticle]:
        """
        ä½å“è³ªãƒ»ã‚¹ãƒ‘ãƒ è¨˜äº‹ã‚’é™¤å¤–
        
        ãƒã‚§ãƒƒã‚¯é …ç›®ï¼š
        - ã‚¿ã‚¤ãƒˆãƒ«é•· >= 10 æ–‡å­—
        - å‰Šé™¤æ¸ˆã¿ãƒãƒ¼ã‚¯ãªã—
        - å…¬é–‹æ—¥ãŒ 72 æ™‚é–“ä»¥å†…
        - æœ¬æ–‡ãŒå­˜åœ¨
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articlesï¼šæ¤œæŸ»å¯¾è±¡ã®è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        æˆ»ã‚Šå€¤ï¼š
            List[UniversalArticle]ï¼šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é€šéã—ãŸè¨˜äº‹
        
        ä½¿ç”¨ä¾‹ï¼š
            filtered = ArticleFilter.filter_articles(articles)
            print(f"{len(articles)} â†’ {len(filtered)} ä»¶")
        """
```

---

### 3.3 ArticleScorer ã‚¯ãƒ©ã‚¹

```python
class ArticleScorer:
    """
    è¨˜äº‹ã®é‡è¦åº¦ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆ0-100ï¼‰
    """

    @staticmethod
    def calculate_score(
        article: UniversalArticle,
        keywords_matched: List[str]
    ) -> int:
        """
        è¨˜äº‹ã®ã‚¹ã‚³ã‚¢ï¼ˆé‡è¦åº¦ï¼‰ã‚’è¨ˆç®—
        
        ã‚¹ã‚³ã‚¢è¨ˆç®—å¼ï¼š
            ã‚¹ã‚³ã‚¢ = 
              ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒåº¦ Ã— 40% +
              è¨˜äº‹ã®é®®åº¦ Ã— 20% +
              ã‚½ãƒ¼ã‚¹ä¿¡é ¼åº¦ Ã— 20% +
              ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è³ª Ã— 20%
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            article (UniversalArticle)ï¼šæ¡ç‚¹å¯¾è±¡ã®è¨˜äº‹
            keywords_matched (List[str])ï¼šãƒãƒƒãƒã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
                ä¾‹ï¼š["AI", "ä¼æ¥­"]
        
        æˆ»ã‚Šå€¤ï¼š
            intï¼šã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        
        ä½¿ç”¨ä¾‹ï¼š
            score = ArticleScorer.calculate_score(article, ["AI"])
            print(f"ã‚¹ã‚³ã‚¢ï¼š{score}")
        """
```

---

### 3.4 KeywordExtractor ã‚¯ãƒ©ã‚¹

```python
class KeywordExtractor:
    """
    è¨˜äº‹ã‹ã‚‰é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡º
    """

    @staticmethod
    def extract(article: UniversalArticle) -> List[str]:
        """
        è¨˜äº‹ã‹ã‚‰é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        
        æŠ½å‡ºæ–¹æ³•ï¼š
        - è¨­å®šæ¸ˆã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰æ¤œç´¢
        - ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æœ¬æ–‡å†…ã®å‡ºç¾ã‚’ãƒã‚§ãƒƒã‚¯
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            article (UniversalArticle)ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå¯¾è±¡
        
        æˆ»ã‚Šå€¤ï¼š
            List[str]ï¼šæŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
                ä¾‹ï¼š["AI", "OpenAI", "è¨€èªãƒ¢ãƒ‡ãƒ«"]
        
        ä½¿ç”¨ä¾‹ï¼š
            keywords = KeywordExtractor.extract(article)
        """
```

---

### 3.5 Deduplicator ã‚¯ãƒ©ã‚¹

```python
class Deduplicator:
    """
    åŒã˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¤‡æ•°å ±é“ã‚’çµ±åˆ
    """

    @staticmethod
    def deduplicate(articles: List[UniversalArticle]) -> List[UniversalArticle]:
        """
        é‡è¤‡è¨˜äº‹ã‚’æ¤œå‡ºãƒ»é™¤å¤–
        
        åˆ¤å®šæ–¹æ³•ï¼š
        - ã‚¿ã‚¤ãƒˆãƒ«ã®æ­£è¦åŒ–ã‚’æ¯”è¼ƒ
        - æ•°å­—ã‚’çµ±ä¸€
        - é¡ä¼¼åº¦åˆ¤å®š
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articlesï¼šé‡è¤‡ãƒã‚§ãƒƒã‚¯å¯¾è±¡
        
        æˆ»ã‚Šå€¤ï¼š
            List[UniversalArticle]ï¼šé‡è¤‡æ’é™¤æ¸ˆã¿è¨˜äº‹
        
        ä½¿ç”¨ä¾‹ï¼š
            dedup = Deduplicator.deduplicate(articles)
            print(f"é‡è¤‡ï¼š{len(articles) - len(dedup)} ä»¶")
        """
```

---

### 3.6 Ranker ã‚¯ãƒ©ã‚¹

```python
class Ranker:
    """
    è¨˜äº‹ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    """

    @staticmethod
    def rank_by_category(articles: List[UniversalArticle]) -> Dict[str, List[UniversalArticle]]:
        """
        ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«è¨˜äº‹ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘
        
        ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–ï¼š
        1. relevance_scoreï¼ˆé™é †ï¼‰
        2. published_atï¼ˆæ–°ã—ã„é †ï¼‰
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articlesï¼šãƒ©ãƒ³ã‚¯å¯¾è±¡ã®è¨˜äº‹
        
        æˆ»ã‚Šå€¤ï¼š
            Dict[str, List]ï¼š{
                "AI": [1ä½, 2ä½, ...],
                "æ±ºç®—": [1ä½, 2ä½, ...],
                ...
            }
        
        ä½¿ç”¨ä¾‹ï¼š
            ranking = Ranker.rank_by_category(articles)
            for category, items in ranking.items():
                print(f"{category}: {len(items)} ä»¶")
        """
```

---

## 4ï¸âƒ£ LLM API

### 4.1 AdaptiveLLMRouter ã‚¯ãƒ©ã‚¹

```python
class AdaptiveLLMRouter:
    """
    ã‚«ãƒ†ã‚´ãƒªãƒ»é›£æ˜“åº¦ã«å¿œã˜ã¦æœ€é©ãª LLM ã‚’è‡ªå‹•é¸æŠ
    """

    async def summarize(
        self,
        article: UniversalArticle,
        category: str
    ) -> Tuple[str, str]:
        """
        è¨˜äº‹ã‚’è¦ç´„ï¼ˆæœ€é©ãª API ã§è‡ªå‹•å®Ÿè¡Œï¼‰
        
        API é¸æŠãƒ­ã‚¸ãƒƒã‚¯ï¼š
        - "AI" â†’ Claudeï¼ˆé«˜ç²¾åº¦ï¼‰
        - "æ±ºç®—" â†’ ChatGPTï¼ˆæ•°å€¤åˆ†æå¾—æ„ï¼‰
        - "ç§‘å­¦" â†’ Claudeï¼ˆè«–æ–‡å¯¾å¿œï¼‰
        - ãã®ä»– â†’ Geminiï¼ˆä½ã‚³ã‚¹ãƒˆï¼‰
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            article (UniversalArticle)ï¼šè¦ç´„å¯¾è±¡
            category (str)ï¼šè¨˜äº‹ã‚«ãƒ†ã‚´ãƒª
        
        æˆ»ã‚Šå€¤ï¼š
            Tuple[str, str]ï¼š(è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ, ä½¿ç”¨ã—ãŸ APIå)
                ä¾‹ï¼š("OpenAI ã¯ GPT-5 ã‚’ç™ºè¡¨...", "claude")
        
        ä¾‹å¤–ï¼š
            Exceptionï¼šå…¨ API ãŒå¤±æ•—
        
        ä½¿ç”¨ä¾‹ï¼š
            summary, api_name = await router.summarize(article, "AI")
            print(f"ä½¿ç”¨ APIï¼š{api_name}")
        """

    async def summarize_with_fallback(
        self,
        article: UniversalArticle,
        category: str
    ) -> Tuple[str, str]:
        """
        ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼å¯¾å¿œã®è¦ç´„ç”Ÿæˆ
        
        å‹•ä½œï¼š
        1. ãƒ¡ã‚¤ãƒ³ API ã§è©¦è¡Œ
        2. å¤±æ•—ã—ãŸã‚‰æ¬¡ã® API ã§è©¦è¡Œ
        3. å…¨ã¦å¤±æ•—ã—ãŸã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            article (UniversalArticle)
            category (str)
        
        æˆ»ã‚Šå€¤ï¼š
            Tuple[str, str]ï¼š(è¦ç´„, APIå)
        
        ä½¿ç”¨ä¾‹ï¼š
            summary, api = await router.summarize_with_fallback(article, "AI")
        """
```

### 4.2 ClaudeClient ã‚¯ãƒ©ã‚¹

```python
class ClaudeClient:
    """
    Claude API ãƒ©ãƒƒãƒ‘ãƒ¼
    """

    async def summarize(
        self,
        text: str,
        max_tokens: int = 200
    ) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            text (str)ï¼šè¦ç´„å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            max_tokens (int)ï¼šæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        
        æˆ»ã‚Šå€¤ï¼š
            strï¼šç”Ÿæˆã•ã‚ŒãŸè¦ç´„
        
        ä½¿ç”¨ä¾‹ï¼š
            summary = await claude.summarize(article_text)
        """
```

---

## 5ï¸âƒ£ Output API

### 5.1 HTMLGenerator ã‚¯ãƒ©ã‚¹

```python
class HTMLGenerator:
    """
    UniversalArticle ã‚’ HTML ã«å¤‰æ›
    """

    @staticmethod
    def generate(
        articles: List[UniversalArticle],
        date: str
    ) -> str:
        """
        è¨˜äº‹ãƒªã‚¹ãƒˆã‚’æ–°èé¢¨ HTML ã«å¤‰æ›
        
        HTML ç‰¹æ€§ï¼š
        - ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆiPad å¯¾å¿œï¼‰
        - æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ
        - ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼ˆå°†æ¥ï¼‰
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articles (List[UniversalArticle])ï¼šå¤‰æ›å¯¾è±¡è¨˜äº‹
            date (str)ï¼šæ—¥ä»˜ï¼ˆ"2026-01-29"ï¼‰
        
        æˆ»ã‚Šå€¤ï¼š
            strï¼šå®Œæˆã—ãŸ HTML
        
        ä½¿ç”¨ä¾‹ï¼š
            html = HTMLGenerator.generate(articles, "2026-01-29")
            with open("news.html", "w") as f:
                f.write(html)
        """
```

### 5.2 MarkdownGenerator ã‚¯ãƒ©ã‚¹

```python
class MarkdownGenerator:
    """
    UniversalArticle ã‚’ Markdown ã«å¤‰æ›
    """

    @staticmethod
    def generate(
        articles: List[UniversalArticle],
        date: str
    ) -> str:
        """
        è¨˜äº‹ãƒªã‚¹ãƒˆã‚’ Markdown ã«å¤‰æ›
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articles (List[UniversalArticle])
            date (str)ï¼šæ—¥ä»˜
        
        æˆ»ã‚Šå€¤ï¼š
            strï¼šMarkdown ãƒ†ã‚­ã‚¹ãƒˆ
        
        ä½¿ç”¨ä¾‹ï¼š
            md = MarkdownGenerator.generate(articles, date)
        """
```

### 5.3 NotionUploader ã‚¯ãƒ©ã‚¹

```python
class NotionUploader:
    """
    Notion ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æŠ•ç¨¿
    """

    async def upload_articles(
        self,
        articles: List[UniversalArticle]
    ) -> bool:
        """
        è¨˜äº‹ãƒªã‚¹ãƒˆã‚’ Notion ã«æŠ•ç¨¿
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
            articles (List[UniversalArticle])
        
        æˆ»ã‚Šå€¤ï¼š
            boolï¼šæˆåŠŸãªã‚‰ True
        
        ä¾‹å¤–ï¼š
            Exceptionï¼šæŠ•ç¨¿å¤±æ•—
        
        ä½¿ç”¨ä¾‹ï¼š
            success = await uploader.upload_articles(articles)
        """
```

---

## 6ï¸âƒ£ ãƒ¡ã‚¤ãƒ³å‡¦ç† API

### 6.1 main() é–¢æ•°

```python
async def main():
    """
    Digest Daily ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
    
    ãƒ•ãƒ­ãƒ¼ï¼š
    1. ãƒ‡ãƒ¼ã‚¿å–å¾—
    2. æ­£è¦åŒ–ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    3. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ»è¦ç´„ç”Ÿæˆ
    4. HTML/Markdown/Notion ã«å‡ºåŠ›
    
    ä½¿ç”¨ä¾‹ï¼š
        asyncio.run(main())
    """
```

---

## 7ï¸âƒ£ ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰å®šç¾©

```python
ã€ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã€‘

class NewsSourceError(Exception):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼"""

class NormalizationError(Exception):
    """ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼"""

class LLMError(Exception):
    """LLM å‡¦ç†ã‚¨ãƒ©ãƒ¼"""

class OutputError(Exception):
    """å‡ºåŠ›å‡¦ç†ã‚¨ãƒ©ãƒ¼"""

ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä¾‹ã€‘

try:
    articles = await fetcher.fetch_all()
except NewsSourceError as e:
    logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ï¼š{e}")
    # ä»–ã®ã‚½ãƒ¼ã‚¹ã¯ç¶™ç¶š
except Exception as e:
    logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ï¼š{e}")
```

---

## 8ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆå†æ²ï¼‰

```python
@dataclass
class UniversalArticle:
    # ã€å¿…é ˆã€‘
    id: str                          # è¨˜äº‹ä¸€æ„ ID
    title: str                       # ã‚¿ã‚¤ãƒˆãƒ«
    source_url: str                  # å…ƒè¨˜äº‹ URL
    source_name: str                 # ã‚½ãƒ¼ã‚¹å
    published_at: datetime           # å…¬é–‹æ—¥æ™‚
    fetched_at: datetime             # å–å¾—æ—¥æ™‚
    source_type: str                 # ã‚½ãƒ¼ã‚¹ç¨®åˆ¥
    category: str                    # ã‚«ãƒ†ã‚´ãƒª
    
    # ã€å‡¦ç†å¾Œã€‘
    summary: Optional[str] = None    # è¦ç´„
    keywords: Optional[List[str]] = None  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    relevance_score: Optional[int] = None  # 0-100 ã‚¹ã‚³ã‚¢
```

---

## 9ï¸âƒ£ åˆ©ç”¨ä¾‹ï¼šãƒ•ãƒ« ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
# src/main.py ã®ä½¿ç”¨ä¾‹

import asyncio
from src.data_sources.newsapi_source import NewsAPISource
from src.llm.router import AdaptiveLLMRouter
from src.outputs.html_generator import HTMLGenerator

async def main():
    # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
    fetcher = DataFetcher()
    articles = await fetcher.fetch_all()
    print(f"âœ… {len(articles)} ä»¶å–å¾—")
    
    # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered = ArticleFilter.filter_articles(articles)
    print(f"âœ… {len(filtered)} ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é€šé")
    
    # 3. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    for article in filtered:
        score = ArticleScorer.calculate_score(article, article.category)
        article.relevance_score = score
    
    # 4. è¦ç´„ç”Ÿæˆ
    router = AdaptiveLLMRouter()
    for article in filtered:
        summary, api = await router.summarize(article, article.category)
        article.summary = summary
        print(f"âœ… {api} ã§è¦ç´„ç”Ÿæˆ")
    
    # 5. HTML å‡ºåŠ›
    html = HTMLGenerator.generate(filtered, "2026-01-29")
    with open("news/2026-01-29.html", "w") as f:
        f.write(html)
    
    print("âœ… å®Œæˆï¼")

if __name__ == '__main__':
    asyncio.run(main())
```

---

**ã“ã‚ŒãŒã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ã® API ä»•æ§˜ã§ã™ï¼**
