# Logic Detailed - ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°èª¬æ˜

## ğŸ“Š å…¨ä½“ãƒ•ãƒ­ãƒ¼

```
å–å¾—ã—ãŸè¨˜äº‹
    â†“
ã€1. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‘ä½å“è³ªãƒ»ã‚¹ãƒ‘ãƒ é™¤å¤–
    â†“
ã€2. æ­£è¦åŒ–ã€‘è¤‡æ•°ã‚½ãƒ¼ã‚¹ã®å½¢å¼ã‚’çµ±ä¸€
    â†“
ã€3. ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‘é‡è¦åº¦ã‚’æ•°å€¤åŒ–ï¼ˆ0-100ï¼‰
    â†“
ã€4. è¦ç´„ç”Ÿæˆã€‘Claude ã§æ—¥æœ¬èªè¦ç´„
    â†“
ã€5. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã€‘é‡è¦å˜èªã‚’è‡ªå‹•æŠ½å‡º
    â†“
ã€6. é‡è¤‡æ’é™¤ã€‘åŒã˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’çµ±ä¸€
    â†“
ã€7. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘ã‚¹ã‚³ã‚¢é †ã«æ•´åˆ—
    â†“
æœ€çµ‚çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
```

---

## 1ï¸âƒ£ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä½å“è³ªè¨˜äº‹é™¤å¤–ï¼‰

### ç›®çš„
ã‚¹ãƒ‘ãƒ ã€å‰Šé™¤æ¸ˆã¿è¨˜äº‹ã€çŸ­ã™ãã‚‹è¨˜äº‹ãªã©ã€å“è³ªã®ä½ã„è¨˜äº‹ã‚’é™¤å¤–ã€‚

```python
# src/core/filter.py

class ArticleFilter:
    """
    è¨˜äº‹ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    FILTER_RULES = {
        'min_title_length': 10,        # ã‚¿ã‚¤ãƒˆãƒ«æœ€å° 10 æ–‡å­—
        'min_content_length': 50,      # æœ¬æ–‡æœ€å° 50 æ–‡å­—
        'max_article_age_hours': 72,   # 72 æ™‚é–“ä»¥ä¸Šå¤ã„è¨˜äº‹ã¯é™¤å¤–
        'blacklist_titles': ['[Removed]', '[Deleted]'],  # å‰Šé™¤æ¸ˆã¿ãƒãƒ¼ã‚¯
    }
    
    @staticmethod
    def filter_articles(articles: list) -> list:
        """
        è¨˜äº‹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        æˆ»ã‚Šå€¤ï¼š
            list: ãƒ•ã‚£ãƒ«ã‚¿ã‚’é€šéã—ãŸè¨˜äº‹
        """
        filtered = []
        
        for article in articles:
            # âŒ ã‚¿ã‚¤ãƒˆãƒ«ãŒãªã„ OR çŸ­ã™ãã‚‹
            if not article.title or \
               len(article.title) < ArticleFilter.FILTER_RULES['min_title_length']:
                continue
            
            # âŒ å‰Šé™¤æ¸ˆã¿ãƒãƒ¼ã‚¯
            if any(mark in article.title for mark in ArticleFilter.FILTER_RULES['blacklist_titles']):
                continue
            
            # âŒ æœ¬æ–‡ãŒãªã„ OR çŸ­ã™ãã‚‹
            if article.summary is None or \
               len(article.summary) < ArticleFilter.FILTER_RULES['min_content_length']:
                continue
            
            # âŒ å¤ã™ãã‚‹ï¼ˆ72 æ™‚é–“ä»¥ä¸Šå‰ï¼‰
            from datetime import datetime, timedelta, timezone
            age_hours = (datetime.now(timezone.utc) - article.published_at).total_seconds() / 3600
            if age_hours > ArticleFilter.FILTER_RULES['max_article_age_hours']:
                continue
            
            # âœ… ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’é€šé
            filtered.append(article)
        
        return filtered
```

---

## 2ï¸âƒ£ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆé‡è¦åº¦è¨ˆç®—ï¼‰

### è¨ˆç®—å¼

```
ã‚¹ã‚³ã‚¢ = 
  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒåº¦ Ã— 40% +
  è¨˜äº‹ã®é®®åº¦ Ã— 20% +
  ã‚½ãƒ¼ã‚¹ä¿¡é ¼åº¦ Ã— 20% +
  ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è³ª Ã— 20%
```

### è©³ç´°å®Ÿè£…

```python
# src/core/scorer.py

from datetime import datetime, timezone

class ArticleScorer:
    """
    è¨˜äº‹ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    KEYWORD_WEIGHT = 0.40
    RECENCY_WEIGHT = 0.20
    CREDIBILITY_WEIGHT = 0.20
    QUALITY_WEIGHT = 0.20
    
    CREDIBILITY_MAP = {
        'Nature': 20,
        'arXiv': 18,
        'æ—¥çµŒæ–°è': 18,
        'TechCrunch': 16,
        'Reuters': 17,
        # ... ãã®ä»–ã®ã‚½ãƒ¼ã‚¹
    }
    
    @staticmethod
    def calculate_score(article, keywords_matched: list) -> int:
        """
        è¨˜äº‹ã®ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ã‚’è¨ˆç®—
        """
        score = 0
        
        # ===== 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒåº¦ï¼ˆ40%ï¼‰=====
        # ãƒãƒƒãƒã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒå¤šã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
        keyword_matches = len([
            kw for kw in keywords_matched
            if kw.lower() in article.title.lower() or \
               kw.lower() in (article.summary or '').lower()
        ])
        keyword_score = min(keyword_matches * 20, 40)  # æœ€å¤§ 40
        score += keyword_score
        
        # ===== 2. è¨˜äº‹ã®é®®åº¦ï¼ˆ20%ï¼‰=====
        # æœ€è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã»ã©é«˜ã‚¹ã‚³ã‚¢
        hours_old = (datetime.now(timezone.utc) - article.published_at).total_seconds() / 3600
        
        if hours_old < 1:
            recency_score = 20  # 1 æ™‚é–“ä»¥å†…
        elif hours_old < 6:
            recency_score = 15  # 6 æ™‚é–“ä»¥å†…
        elif hours_old < 24:
            recency_score = 10  # 24 æ™‚é–“ä»¥å†…
        else:
            recency_score = 5
        
        score += recency_score
        
        # ===== 3. ã‚½ãƒ¼ã‚¹ä¿¡é ¼åº¦ï¼ˆ20%ï¼‰=====
        source_credibility = ArticleScorer.CREDIBILITY_MAP.get(
            article.source_name, 10  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 10
        )
        score += source_credibility
        
        # ===== 4. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è³ªï¼ˆ20%ï¼‰=====
        # ã‚¿ã‚¤ãƒˆãƒ«é•·ã€æœ¬æ–‡é•·ã§åˆ¤å®š
        title_length_score = min(len(article.title) // 10, 10)
        summary_length = len(article.summary or '') if article.summary else 0
        summary_length_score = min(summary_length // 50, 10)
        quality_score = (title_length_score + summary_length_score) / 2
        
        score += quality_score
        
        return int(min(score, 100))  # æœ€å¤§ 100
```

---

## 3ï¸âƒ£ è¦ç´„ç”Ÿæˆ

### æ‰‹é †

```python
# src/llm/claude_client.py

class ClaudeClient:
    
    async def summarize(self, article) -> str:
        """
        è¨˜äº‹ã‚’è¦ç´„ç”Ÿæˆ
        """
        prompt = f"""
æ¬¡ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ã€ç°¡æ½”ãªæ—¥æœ¬èªã§2-3æ–‡ã®è¦ç´„ã«ã—ã¦ãã ã•ã„ã€‚
æ­£ç¢ºæ€§ã‚’é‡è¦–ã—ã€ä¸»è¦³çš„ãªè©•ä¾¡ã¯å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚

ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{article.title}

ã€æœ¬æ–‡ã€‘
{article.original_data.get('content', '')[:500]}

ã€è¦ç´„ã€‘
"""
        
        message = self.client.messages.create(
            model="claude-opus-4-5-20251101",
            max_tokens=200,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return message.content[0].text.strip()
```

---

## 4ï¸âƒ£ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º

```python
# src/core/keyword_extractor.py

class KeywordExtractor:
    
    @staticmethod
    def extract(article) -> list:
        """
        è¨˜äº‹ã‹ã‚‰é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡º
        """
        text = f"{article.title} {article.summary or ''}"
        
        # è¨­å®šæ¸ˆã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        matched = []
        for keyword in KEYWORD_MAPPING.keys():
            if keyword.lower() in text.lower():
                matched.append(keyword)
        
        return list(set(matched))  # é‡è¤‡æ’é™¤
```

---

## 5ï¸âƒ£ é‡è¤‡æ’é™¤

```python
# src/core/deduplicator.py

class Deduplicator:
    
    @staticmethod
    def deduplicate(articles: list) -> list:
        """
        åŒã˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¤‡æ•°å ±é“ã‚’çµ±åˆ
        """
        seen = {}
        deduplicated = []
        
        for article in articles:
            # ã‚¿ã‚¤ãƒˆãƒ«ã®æ­£è¦åŒ–ï¼ˆæ•°å­—ã‚’çµ±ä¸€ï¼‰
            import re
            normalized = re.sub(r'\d+', '0', article.title.lower())
            
            if normalized in seen:
                # æ—¢ã«è¦‹ãŸä¼¼ãŸè¨˜äº‹
                existing = seen[normalized]
                # ã‚¹ã‚³ã‚¢ãŒé«˜ã„æ–¹ã‚’ä¿æŒ
                if article.relevance_score > existing.relevance_score:
                    deduplicated.remove(existing)
                    deduplicated.append(article)
            else:
                seen[normalized] = article
                deduplicated.append(article)
        
        return deduplicated
```

---

## 6ï¸âƒ£ ãƒ©ãƒ³ã‚­ãƒ³ã‚°

```python
# src/core/ranker.py

class Ranker:
    
    @staticmethod
    def rank_by_category(articles: list) -> dict:
        """
        ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«è¨˜äº‹ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘
        """
        by_category = {}
        
        for article in articles:
            if article.category not in by_category:
                by_category[article.category] = []
            by_category[article.category].append(article)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã‚’ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        for category in by_category:
            by_category[category] = sorted(
                by_category[category],
                key=lambda x: (x.relevance_score, x.published_at),
                reverse=True
            )
        
        return by_category
```

---

## ğŸ“ˆ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ä¾‹

```
ã€ä¾‹ 1ã€‘
ã‚¿ã‚¤ãƒˆãƒ«ï¼š"OpenAI ãŒ GPT-5 ã‚’ç™ºè¡¨"
ã‚½ãƒ¼ã‚¹ï¼š"TechCrunch"
å…¬é–‹ ï¼š2 æ™‚é–“å‰
ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š"AI"

è¨ˆç®—ï¼š
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ40%ï¼‰ï¼š1 å€‹ãƒãƒƒãƒ Ã— 20 = 20
- é®®åº¦ï¼ˆ20%ï¼‰ï¼š2 æ™‚é–“å‰ = 15
- ä¿¡é ¼åº¦ï¼ˆ20%ï¼‰ï¼šTechCrunch = 16
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è³ªï¼ˆ20%ï¼‰ï¼šã‚¿ã‚¤ãƒˆãƒ«é•·ãƒ»æœ¬æ–‡é•· = 15

åˆè¨ˆã‚¹ã‚³ã‚¢ï¼š20 + 15 + 16 + 15 = 66


ã€ä¾‹ 2ã€‘
ã‚¿ã‚¤ãƒˆãƒ« ï¼š"ãƒˆãƒ¨ã‚¿ã®å–¶æ¥­åˆ©ç›Š 28% å¢—"
ã‚½ãƒ¼ã‚¹ï¼š"EDINETï¼ˆæ—¥æœ¬ä¼æ¥­æ±ºç®—ï¼‰"
å…¬é–‹ï¼š1 æ—¥å‰
ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š"æ±ºç®—"

è¨ˆç®—ï¼š
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ40%ï¼‰ï¼š1 å€‹ãƒãƒƒãƒ Ã— 20 = 20
- é®®åº¦ï¼ˆ20%ï¼‰ï¼š24 æ™‚é–“å‰ = 10
- ä¿¡é ¼åº¦ï¼ˆ20%ï¼‰ï¼šé‡‘èæƒ…å ±æº = 18
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è³ªï¼ˆ20%ï¼‰ï¼šã‚¿ã‚¤ãƒˆãƒ«é•·ãƒ»æœ¬æ–‡é•· = 17

åˆè¨ˆã‚¹ã‚³ã‚¢ï¼š20 + 10 + 18 + 17 = 65
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆä¾‹

```python
# tests/test_scorer.py

def test_scoring():
    """
    ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹ã‹
    """
    article = UniversalArticle(
        id="test1",
        title="AI ã®æ–°å±•é–‹",
        source_name="TechCrunch",
        published_at=datetime.now() - timedelta(hours=2),
        fetched_at=datetime.now(),
        summary="AI ãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸ"
    )
    
    score = ArticleScorer.calculate_score(article, ['AI'])
    
    # ã‚¹ã‚³ã‚¢ãŒ 0-100 ã®ç¯„å›²
    assert 0 <= score <= 100
    
    # "AI" ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒã§é«˜ã‚¹ã‚³ã‚¢
    assert score > 50
```

---

**æ¬¡ã¯ MULTI_API_ROUTING.md ã‚’èª­ã‚“ã§ãã ã•ã„ï¼**
